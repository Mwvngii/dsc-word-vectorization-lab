


import pandas as pd
import numpy as np
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
%matplotlib inline
from sklearn.manifold import TSNE
from nltk.tokenize import word_tokenize
import nltk
nltk.download('punkt', quiet=True)
np.random.seed(0)





filenames = [f"data/song{i}.txt" for i in range(1, 21)]





# Import and print song18.txt
with open('data/song18.txt') as f:
    test_song = f.readlines()
    
test_song








def clean_song(song):
    song = [line for line in song if '[' not in line and']' not in line]
    song = ''.join(song)
    song = song.replace('\n', '')
    for punc in ".,'?!()":
        song = song.replace(punc, '')
        song = song.lower()
        return song

clean_test_song = clean_song(test_song)
print(clean_test_song)





tokenized_test_song = word_tokenize(clean_test_song)








def count_vectorize(tokenized_song):
    word_freq = {}
    for word in tokenized_song:
        if word in word_freq:
            word_freq[word] += 1
        else:
            word_freq[word] = 1
    return word_freq

test_vectorized = count_vectorize(tokenized_test_song)
print(test_vectorized)








def inverse_document_frequency(list_of_token_songs):
    import math
    num_docs = len(list_of_token_songs)
    word_doc_count = {}
    
    for song in list_of_token_songs:
        unique_words = set(song)
        for word in unique_words:
            if word in word_doc_count:
                word_doc_count[word] += 1
            else:
                word_doc_count[word] = 1
                
                
    idf = {word: math.log(num_docs/ count)
for word, count in word_doc_count.items()}
    return idf





def tf_idf(list_of_token_songs):
    idf = inverse_document_frequency(list_of_token_songs)
    tf_idf_values = []

    for song in list_of_token_songs:
        song_tf = count_vectorize(song)
        tf_idf_song = {word:
                       song_tf.get(word, 0) * idf.get(word, 0) for word in idf}
        tf_idf_values.append(tf_idf_song)
        
    return tf_idf_values





def main(filenames):
    raw_songs = []
    tokenized_songs = []

    for filename in filenames:
        with open(filename) as f:
            song = f.readlines()
            clean_song_text = clean_song(song)
            tokenized_song = word_tokenize(clean_song_text)
            tokenized_songs.append(tokenized_song)
    return tf_idf(tokenized_songs)
tf_idf_all_docs = main(filenames)





num_dims = len(tf_idf_all_docs[0])
print(f"Number of Dimensions: {num_dims}")





tf_idf_vals_list = [list(doc.values()) for doc in tf_idf_all_docs]

tf_idf_vals_list[0][:10]





from sklearn.manifold import TSNE
t_sne_object_3d = TSNE(n_components=3, perplexity=19, learning_rate=200, init='random', random_state=13)

transformed_data_3d = t_sne_object_3d.fit_transform(np.array(tf_idf_vals_list))
transformed_data_3d





t_sne_object_2d = TSNE(n_components=2, perplexity=19, learning_rate=200, init='random', random_state=13)

transformed_data_2d = t_sne_object_2d.fit_transform(np.array(tf_idf_vals_list))
transformed_data_2d





kendrick_3d = transformed_data_3d[:10]
k3_x = [i[0] for i in kendrick_3d]
k3_y = [i[1] for i in kendrick_3d]
k3_z = [i[2] for i in kendrick_3d]

garth_3d = transformed_data_3d[10:]
g3_x = [i[0] for i in garth_3d]
g3_y = [i[1] for i in garth_3d]
g3_z = [i[2] for i in garth_3d]

fig = plt.figure(figsize=(10,5))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(k3_x, k3_y, k3_z, c='b', s=60, label='Kendrick')
ax.scatter(g3_x, g3_y, g3_z, c='red', s=60, label='Garth')
ax.view_init(40,10)
ax.legend()
plt.show()

kendrick_2d = transformed_data_2d[:10]
k2_x = [i[0] for i in kendrick_2d]
k2_y = [i[1] for i in kendrick_2d]

garth_2d = transformed_data_2d[10:]
g2_x = [i[0] for i in garth_2d]
g2_y = [i[1] for i in garth_2d]

fig = plt.figure(figsize=(20,10))
ax = fig.add_subplot(222)
ax.scatter(k2_x, k2_y, c='b', label='Kendrick')
ax.scatter(g2_x, g2_y, c='red', label='Garth')
ax.legend()
plt.show()









